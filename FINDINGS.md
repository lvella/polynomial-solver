# Satisfiability of Systems of Polynomial (In)Equations in Prime Field

Given a system of polynomial statements, like the following:
$$
4x^3 + 2x^2y^2 + 12x - y = 5 \\
y^3 - 3x^2 \neq 7xy^3 +1 \\
y \neq x,
$$
the goal is to find if there is an evaluation of the variables ($x$ and $y$ in this case) in a field
mod some prime $p$ where all the statements are true. This can be eventually integrated into a SMT
solver, like Z3, and be used to prove statements about zkSNARKs circuits, as generated by ZoKrates.

It seems that inequations of the kind $x^2~\le~y$ does not really make sense in a mod $p$ field,
because the values wrap around, so a total ordering among the elements is not really meaningfully 
defined for most applications of the satisfiability solver. Alternatively, ranges of the kind
$a~\le~x^2~-~y~\lt~b$ looks much more useful, but I am not sure they will be in the scope of this
work, because I do not know if they would be useful for the goal of proving statements about zkSNARKs
circuits, so this work will be restricted to $=$ and $\neq$ constraints.

## Turning into a system of equations

The problem above can be reduced to the problem of finding the zeros of a set of polynomials,
i.e. the value of $\bm{x}$ such that $f_1(\bm{x})~=~f_2(\bm{x})~=~...~=~f_m(\bm{x})~=~0$, where
$x$ is the vector $(x_1, x_2, ..., x_n)$. For the equalities is easy, just rearrange all terms to
the left-hand side, leaving 0 on the right-hand side. The equality in the example above will became
the polynomial:
$$
f_1 = 4x^3 + 2x^2y^2 + 12x - y - 5
$$

For the differences, we can use the "Rabinowitsch trick" (originally used in a proof of Hilbert's
Nullstellensatz), to turn all the differences into a single equation. We first isolate all terms
on the left-hand side, introduce a new variable $z$, and produce the following equation:
$$
zg_1g_2...g_k - 1 = 0
$$
where $g_i$ are the $\neq 0$ polynomials. This works because the equation only have a solution if
$z$ is the inverse of $g_1g_2...g_k$, and zero has no inverse. In other words, if any of the $g_i$
is zero, the term $g_1g_2...g_k$ vanishes and the remaining equation $-1=0$ has no solutions.

In the above example, the inequations will produce the following polynomial:
$$
f_2 = z (y^3 - 3x^2 - 7xy^3 - 1)(y - x) - 1
$$

The problem is then reduced to the problem of finding the common roots for a set of polynomials (that
belongs in the prime field, obviously, because roots of polynomials may not be defined in the same set
as the coefficients, for instance $x^2~-~2~=~0$ has no solution in integers and $x^2~+~2~=~0$ has no
solution in reals) and exclude all solutions that does not match the variables restrictions.

### Optimization idea

It might prove beneficial to use the square-free component of the polynomials (and also of $g_1g_2...g_k$.
in case of the polynomial from the inequalities), and not the of the original polynomials. This is
because square-free decomposition is cheap, may reduce the degree and size of the polynomial, simplifying
the solving procedure, and the solution is identical (except maybe for the introduced variable $z$, which
is not important to the problem).

## Solving a system of polynomial equations

Since we reduced our problem to a system of polynomial equations, we now have to solve it. I will now
describe the alternatives I am considering to solve it, and where I stand. I will assume the degrees of
the input polynomials are small (not much larger than 10) and the prime field is large (around $2^{254}$).

But before we try any expensive solving algorithm, lets get out of the way some special cases
that are easily handled. It is convenient to first try to reduce the set of polynomials
against itself (which is a step of any Gröbner Basis algorithm, see below), so that the system
is sanitized (all trivial zeros and obviously equivalent polynomials are removed), and some easy to
spot relations might be exposed, thus reducing the degree of some polynomials.

Special case #1: if the set of polynomials is empty, we consider it vacuously
satisfiable and finish. I don't see a good justification for an empty set to be considered
unsatisfiable, on the contrary: trivial zero polynomials are excluded during self-reduction, as they
don't affect the ideal in any way, which leaves the empty set in case the system is the single
polynomial $0$, which is an obviously and trivially solvable by any possible variable evaluation.

Special case #2: non-zero constant polynomial case: if the self-reduction returns a set
with a non-zero constant polynomial (and in this case, reduction definition guarantees it will be
the only polynomial left), it obviously can not be zero, so the system is unsatisfiable. In the
current implementation of reduction, if a non-zero constant polynomial is ever encountered, the
algorithm is cut short and returns immediately so we don't waste more time.

Then we iterate through all the polynomials and count 3 things: the maximum degree of the system $d$,
the number of variables $n$, and the total number of zero degree terms $t_z$.

Special case #3: if $t_z = 0$, there are no zero degree terms, then $(0,0,...,0)$ is a solution of the
system, so we can stop.

Special case #4: if $d = 1$ (can't be 0 because that was checked in special case #1 and #2) then system
is linear. Reduction is the generalization of a Gaussian elimination, so whatever remained of the system
is necessarily solvable. We can stop, and the system is already in triangular form, so it is trivial
to compute the unique solution.

Special case #5: if $n = 1$, reduction guarantees there will be only one polynomial left, since it is
monic, we can extract some root by using Cantor-Zassenhaus probabilistic algorithm (not implemented yet).

Special case #6: not implemented and not sure if it is worth, but in case of a single polynomial with
$n > 1$, [[1](#r1)] suggests factoring into irreducible factors: if any of the factors is absolutely
irreducible (there is a test for that [[3](#r3)]) then we consider it satisfiable and we are done (there
is a theorem that guarantees plenty of solutions if $d$ and $n$ are small enough compared to
the field size [[1](#r1),[2](#r2)]). Each factor $f$ can then be handled independently like the following
(even less sure if it is worth): recursively test if the system $\{f = df/dx = 0\}$ is satisfiable for
some variable $x$ where $df/dx_i$ does not vanishes. The problem is satisfiable iff at least one of these
subsystems spawned by the factors is satisfiable.

I ran out of ideas for special cases, so now I will discuss the alternatives being explored for the
general case.

## Methods based on Gröbner Basis

Finding the reduced Gröbner basis of the polynomial set is often the first step for solving the system.
The best know algorithms for finding Gröbner basis are Faugère's F4 and F5
algorithms, and they have exponential complexity on the worst case. The Gröbner basis is defined for
a total order among the monomials (i.e. the variable product power parts like $x^3y^2$), which implies
a total order among the variables themselves. Each ordering has some useful properties: reverse
degree lexicographical order (degrevlex), also called graded reverse lexicographic order (grevlex)
is the fastest to calculate (exponential instead of double exponential). Lexicographical ordering
leaves the system in triangular format suitable for variable elimination.

Right now all I have implemented of this method is a quite bad version of Buchberger's algorithm,
which is much worse in practice than Faugère's F4 and F5 (but have the same worst case complexity),
which for a very small system is capable of computing the Gröbner basis in grevlex ordering, but I
don't believe it would terminate in a human lifetime for lexicographical ordering.

### Triangular system

For this approach, we need the Gröbner basis in lexicographical order, so that the system is in a
triangular format where we can eliminate one variable at a time. But Gröbner basis is much faster to
calculate on grevlex, so much that in practice lexicographical order is obtained by transforming from
grevlex via Gröbner Walk or some algorithm of the sort. According to [[4](#r4)], this order conversion
step is the slowest in this approach.

This will yield a new set of polynomials with the same roots, but in a triangular format, i.e. that
once the free variables are assigned arbitrarily, the system can be solved one variable a time, so
that the first polynomial has only one variable to be solved, which will leave the next polynomial
with only one variable after replacing the variables already known, and so forth until the system is
completely solved. 

For instance, in a 3 variable systems, if we define $x > y > z > 1$ in our ordering (1 must always be
the smallest), then the first variable that can be solved is $z$, then $y$, then $x$, assuming the
system is fully determined. If the system is not fully determined, and there are free variables, then
the lowest variables are the ones to be assigned.

Having an algorithm to find the roots one variable at a time, we have a branching problem, where each
variable assignment will lead to a new set of possible assignments for the next variable, and so on,
so that the naïve search expands into a typical NP problem.

Finding roots of a univariate polynomial in a prime field is relatively cheap, with the best known
algorithm being factorizing the polynomial into unique factors $(x - a_1)(x - a_2)...(x - a_n)$ where
$a_i$ are the roots of the polynomial. The most efficient algorithm for factorization in a prime
field is called Cantor-Zassenhaus algorithm, with complexity $O(d^3 \log p)$ where $d$ is the degree
of the polynomial and $p$ is the prime field's prime.

Nothing besides the bad Gröbner basis in grevlex is implemented for this approach, being Gröbner Walk (or
some alternative) and Cantor-Zassenhaus the most notable absences.

The unsolved problems of this approach includes how to choose the variable ordering optimally and
how the search for a variable assignment in the triangular system that is better than exhaustive
trial and error. It is unclear how to perform a local search in the triangular system, much less
how to prove unsatisfiability. Maybe [4] can shed a light into this.

### Base field restriction

The satisfiability problem can be solved by finding the Gröbner basis of the system extended with the
equations
$$
x^p - x = 0
$$
for each variable $x$ in the system (as per Fermat's little theorem, $x^p = x \mod p$). This will
remove all roots lying on the extension field but not in the base field.

For instance, for the system:
$$
f_1 = 4x^3 + 2x^2y^2 + 12x - y - 5 \\
f_2 = z (y^3 - 3x^2 - 7xy^3 - 1)(y - x) - 1 \\
$$
the new polynomials would be:
$$
f_3 = x^p - x\\
f_4 = y^p - y\\
f_5 = z^p - z
$$
where $p$ is the prime of the field.

The Gröbner basis of the extended set will contain a constant iff the system is unsatisfiable. Such Gröbner
basis can be calculated using any monomial ordering, like degree reverse lexicographical order, which is
cheaper to calculate than the lexicographical order.

I don't know how to turn this into a practical algorithm for the case where $p \gg 0$, as the procedure to
calculate the Gröbner basis is prohibitively expensive due to the time complexity being $O(p^2)$ on the
reduction step of $x^p - x = 0$. I suspect it can be done in $O(p \log p)$ by using exponentiation by
squaring, but even that is impractical, and wouldn't help with the huge size of each reduced polynomial would
have (on the order of $O(p)$). Maybe there can be a compact representation of the polynomial, but
still don't look promising... 

### Primary decomposition Method

TODO

## SIMPLEX generalization

In linear systems, the search can be reduced by looking at the bounds of the variables with the
SIMPLEX algorithm, so maybe there is a SIMPLEX generalization that works here to speed-up the search,
but I find it unlikely, as SIMPLEX works by iteratively restricting the convex search space limited
by straight lines/hyperplanes, but the curves designated by non-linear polynomials are not planes, so
the limited space will not be convex.

I just barely considered this alternative.

## Robust Algebraic Geometry Method

TODO

## Fast Algebraic Geometry Method

TODO

## References

[<a id="r1">1</a>]: [*Solving systems of polynomial congruences modulo a large prime* (1996), by Ming-Deh Huang and Yiu-Chung Wong](https://doi.org/10.1109/SFCS.1996.548470)

[<a id="r2">2</a>]: [*Fast Computation of a Rational Point of a Variety over a Finite Field* (2006), by Antonio Cafure and Guillermo Matera](https://www.jstor.org/stable/4100138)

[<a id="r3">3</a>]: [*Fast parallel absolute irreducibility testing* (1985), by Erich Kaltofen](https://doi.org/10.1016/S0747-7171(85)80029-8)

[<a id="r4">4</a>]: ???